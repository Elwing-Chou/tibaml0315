{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaAFceTmmDSYZvuTb1EuWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Elwing-Chou/tibaml0315/blob/main/imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0y2OyYDfe8G",
        "outputId": "6b75ea09-baaf-430d-839a-e03937d0d745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 5s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "def getdata(mid):\n",
        "    dn = os.path.dirname(dataset)\n",
        "    posfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"pos\", \"*\"))\n",
        "    negfn = glob.glob(os.path.join(dn, \"aclImdb\", mid, \"neg\", \"*\"))\n",
        "    contents = []\n",
        "    for fn in posfn + negfn:\n",
        "        with open(fn, encoding=\"utf-8\") as f:\n",
        "            contents.append(f.read())\n",
        "    df = pd.DataFrame({\n",
        "        \"content\":contents,\n",
        "        \"sentiment\":[1] * len(posfn) + [0] * len(negfn)\n",
        "    })\n",
        "    return df\n",
        "train_df = getdata(\"train\")\n",
        "test_df = getdata(\"test\")"
      ],
      "metadata": {
        "id": "tLi-Fe6zfl4M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "Q7E_-8mogCCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "# 3000種常用詞彙+1padding(0): 美一篇文章進入的時候只取512在常用詞彙列表的詞, 每一個詞化做100維度的語意像量\n",
        "layers = [\n",
        "    # 沒有激活, 3001(種詞彙) * 100 -> 300100\n",
        "    Embedding(input_dim=3001, output_dim=100, mask_zero=True, input_length=512),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "]\n",
        "model = Sequential(layers)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jHXDnv-Uy2E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "model.compile(loss=SparseCategoricalCrossentropy(),\n",
        "       metrics=[\"accuracy\"],\n",
        "       optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "QvptZClA5tA3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize: 詞彙換成數字, 建立一個3000常用詞彙辭典\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tok = Tokenizer(num_words=3000)\n",
        "tok.fit_on_texts(train_df[\"content\"])"
      ],
      "metadata": {
        "id": "bL8pdwvf5u_I"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tok.word_index\n",
        "# tok.index_word\n",
        "# 檢查: 這個case, 標點和換行是可以去掉的\n",
        "# tok.word_index[\"?\"]\n",
        "# 停用詞(忽略一些無意義的): 不用, 根據答案就會把無意義的東西調整出來"
      ],
      "metadata": {
        "id": "WlFIWPpa6VDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Sequenize: 把我的字轉換成數字(利用剛剛列表)\n",
        "x_train_seq = tok.texts_to_sequences(train_df[\"content\"])\n",
        "x_test_seq = tok.texts_to_sequences(test_df[\"content\"])\n",
        "pd.DataFrame(x_train_seq)"
      ],
      "metadata": {
        "id": "O5Hn9oPP7seD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train_pad = pad_sequences(x_train_seq, maxlen=512)\n",
        "x_test_pad = pad_sequences(x_test_seq, maxlen=512)\n",
        "pd.DataFrame(x_train_pad)"
      ],
      "metadata": {
        "id": "bRLGpZYW-cmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_train = np.array(train_df[\"sentiment\"])\n",
        "y_test = np.array(test_df[\"sentiment\"])"
      ],
      "metadata": {
        "id": "s0AZB3dC_ulS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "c = [\n",
        "    ModelCheckpoint(\"imdb.h5\", save_best_only=True),\n",
        "    EarlyStopping(patience=5, restore_best_weights=True)\n",
        "]\n",
        "model.fit(x_train_pad,\n",
        "     y_train,\n",
        "     batch_size=100,\n",
        "     epochs=40,\n",
        "     validation_split=0.1,\n",
        "     callbacks=c)"
      ],
      "metadata": {
        "id": "DI-uZtVjBROE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_pad, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdXZaji7CnK2",
        "outputId": "c19c7507-906f-4029-c0b0-92218e2c52b4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2867 - accuracy: 0.8818\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28666284680366516, 0.8818399906158447]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"It's barely even a movie, given it functions mostly as a big, long ad for Nintendo products (Mario games, in this case). It has that lovely Illumination\\u2122 style of humor throughout it all, the stunning shallow writing we've all grown to love from them, and the immaculate character development we certainly expect to be blown away by. It's awful, really. There are so many plot points that make zero sense and function merely as a way of getting the film moving without really adding anything to the story, it all feels infinitely pointless and hollow.  At least the world they built is pretty, that's the one positive.\"#@param {type:\"string\"}\n",
        "seq = tok.texts_to_sequences([review])\n",
        "pad = pad_sequences(seq, maxlen=512)\n",
        "pre = model.predict(pad)\n",
        "prob = pre[0]\n",
        "trans = [\"neg\", \"pos\"]\n",
        "for p, label in zip(prob, trans):\n",
        "    print(label, \"的機率是:\", p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0V5hi7KDm9j",
        "outputId": "b3979380-435f-40fe-8d81-73ad82398d82"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "neg 的機率是: 0.9205835\n",
            "pos 的機率是: 0.07941649\n"
          ]
        }
      ]
    }
  ]
}